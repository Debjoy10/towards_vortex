{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWRo0xalrxpP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AM8cb4iprxpX"
   },
   "outputs": [],
   "source": [
    "# load ascii text \n",
    "filename = \"my_words.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "\n",
    "# OR Write your own:\n",
    "\n",
    "# covert to lowercase\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hollywood's bleeding, vampires feedin'\\ndarkness turns to dust\\neveryone's gone, but no one's leavin'\\nnobody left but us\\ntryna\\u2005chase\\u2005a feelin', but\\u2005we'll never feel it\\nridin' on the\\u2005last train home\\ndyin' in our sleep, we're living out a dream\\nwe only make it out alone\\ni just keep on hopin' that you call me\\nyou say you wanna see me, but you can't right now\\nyou never took the time to get to know me\\nwas scared of losin' somethin' that we never found\\nwe're running out of reasons, but we can't let go\\nyeah, hollywood is bleeding, but we call it home\\noutside, the winter sky turnin' grey\\ncity up in smoke, it's only ash when it rains\\nhowl at the moon and go to sleep in the day\\nlove for everybody 'til the drugs fade away\\nin the mornin', blocking out the sun with the shades\\nshe gotta check her pulse and tell herself that she okay\\nit seem like dying young is an honor\\nbut who'd be at my funeral? i wonder\\ni go out, and all they eyes on me\\ni show out, do you like what you see?\\nand now they closin' in on me\\nlet 'em sharpen all they teeth\\nthis is more than i can handle\\nblood in my lambo'\\nwish i could go, oh, i'm losin' ho-ope\\ni light a candle, some palo santo\\nfor all these demons, wish i could just go on\\ni just keep on hopin' that you call me\\nyou say you wanna see me, but you can't right now\\nyou never took the time to get to know me\\nwas scared of losin' somethin' that we never found\\nwe're running out of reasons, but we can't let go\\nyeah, hollywood is bleeding, but we call it home\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtYJHRNVrxpe"
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Wt8JAhAxrxpi",
    "outputId": "7d631211-cdd8-42ab-df7f-6f7443998bbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " \"'\": 2,\n",
       " ',': 3,\n",
       " '-': 4,\n",
       " '?': 5,\n",
       " 'a': 6,\n",
       " 'b': 7,\n",
       " 'c': 8,\n",
       " 'd': 9,\n",
       " 'e': 10,\n",
       " 'f': 11,\n",
       " 'g': 12,\n",
       " 'h': 13,\n",
       " 'i': 14,\n",
       " 'j': 15,\n",
       " 'k': 16,\n",
       " 'l': 17,\n",
       " 'm': 18,\n",
       " 'n': 19,\n",
       " 'o': 20,\n",
       " 'p': 21,\n",
       " 'r': 22,\n",
       " 's': 23,\n",
       " 't': 24,\n",
       " 'u': 25,\n",
       " 'v': 26,\n",
       " 'w': 27,\n",
       " 'y': 28,\n",
       " '\\u2005': 29}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cFMZzw1prxpn",
    "outputId": "c7ac3c8a-05a1-491a-e77d-0e05c4b94d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1485\n",
      "Total Vocab:  30\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IBzQR8kArxpr",
    "outputId": "37d678e8-4d7b-4005-a45c-8036d60df980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  1385\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AJB9a-onrxpw",
    "outputId": "6395f839-070d-4f83-ddad-76df650e4bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "print(len(dataX[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2UeC1i_rxpz"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rrOQnF5crxp3",
    "outputId": "208ca369-d5a8-4aee-b03d-9e4e63361e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1385, 100, 1)\n",
      "(1385, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBOl5JQbrxp7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1112 00:56:12.800593 140688742917888 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1112 00:56:12.830976 140688742917888 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1112 00:56:12.834806 140688742917888 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1112 00:56:13.189406 140688742917888 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1112 00:56:13.198332 140688742917888 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1112 00:56:13.240620 140688742917888 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1112 00:56:13.272619 140688742917888 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96J09Tqdrxp_"
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "24parC0brxqC",
    "outputId": "5bead389-187c-4273-cf09-07772c16a92a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1112 00:56:17.415277 140688742917888 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1385/1385 [==============================] - 5s 4ms/step - loss: 3.1952\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.19518, saving model to weights-improvement-01-3.1952.hdf5\n",
      "Epoch 2/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9964\n",
      "\n",
      "Epoch 00002: loss improved from 3.19518 to 2.99642, saving model to weights-improvement-02-2.9964.hdf5\n",
      "Epoch 3/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9800\n",
      "\n",
      "Epoch 00003: loss improved from 2.99642 to 2.98005, saving model to weights-improvement-03-2.9800.hdf5\n",
      "Epoch 4/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9720\n",
      "\n",
      "Epoch 00004: loss improved from 2.98005 to 2.97200, saving model to weights-improvement-04-2.9720.hdf5\n",
      "Epoch 5/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9676\n",
      "\n",
      "Epoch 00005: loss improved from 2.97200 to 2.96758, saving model to weights-improvement-05-2.9676.hdf5\n",
      "Epoch 6/20\n",
      "1385/1385 [==============================] - 5s 3ms/step - loss: 2.9684\n",
      "\n",
      "Epoch 00006: loss did not improve from 2.96758\n",
      "Epoch 7/20\n",
      "1385/1385 [==============================] - 5s 4ms/step - loss: 2.9665\n",
      "\n",
      "Epoch 00007: loss improved from 2.96758 to 2.96653, saving model to weights-improvement-07-2.9665.hdf5\n",
      "Epoch 8/20\n",
      "1385/1385 [==============================] - 5s 3ms/step - loss: 2.9690\n",
      "\n",
      "Epoch 00008: loss did not improve from 2.96653\n",
      "Epoch 9/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9645\n",
      "\n",
      "Epoch 00009: loss improved from 2.96653 to 2.96454, saving model to weights-improvement-09-2.9645.hdf5\n",
      "Epoch 10/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9552\n",
      "\n",
      "Epoch 00010: loss improved from 2.96454 to 2.95516, saving model to weights-improvement-10-2.9552.hdf5\n",
      "Epoch 11/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9636\n",
      "\n",
      "Epoch 00011: loss did not improve from 2.95516\n",
      "Epoch 12/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9687\n",
      "\n",
      "Epoch 00012: loss did not improve from 2.95516\n",
      "Epoch 13/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9726\n",
      "\n",
      "Epoch 00013: loss did not improve from 2.95516\n",
      "Epoch 14/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9621\n",
      "\n",
      "Epoch 00014: loss did not improve from 2.95516\n",
      "Epoch 15/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9547\n",
      "\n",
      "Epoch 00015: loss improved from 2.95516 to 2.95471, saving model to weights-improvement-15-2.9547.hdf5\n",
      "Epoch 16/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9570\n",
      "\n",
      "Epoch 00016: loss did not improve from 2.95471\n",
      "Epoch 17/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9579\n",
      "\n",
      "Epoch 00017: loss did not improve from 2.95471\n",
      "Epoch 18/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9604\n",
      "\n",
      "Epoch 00018: loss did not improve from 2.95471\n",
      "Epoch 19/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9587\n",
      "\n",
      "Epoch 00019: loss did not improve from 2.95471\n",
      "Epoch 20/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9552\n",
      "\n",
      "Epoch 00020: loss did not improve from 2.95471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff44cb3c588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4azvZpJRrxqG"
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "PU-_LzarrxqL",
    "outputId": "fb5c4079-2b9d-497f-b25f-2aa363900f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  out, and all they eyes on me\n",
      "i show out, do you like what you see?\n",
      "and now they closin' in on me\n",
      "le \"\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGXgDy6PrxqP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "seqgen_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
