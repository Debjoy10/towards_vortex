{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWRo0xalrxpP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AM8cb4iprxpX"
   },
   "outputs": [],
   "source": [
    "# load ascii text \n",
    "filename = \"my_words.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "\n",
    "# OR Write your own:\n",
    "\n",
    "# covert to lowercase\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hollywood's bleeding, vampires feedin'\\ndarkness turns to dust\\neveryone's gone, but no one's leavin'\\nnobody left but us\\ntryna\\u2005chase\\u2005a feelin', but\\u2005we'll never feel it\\nridin' on the\\u2005last train home\\ndyin' in our sleep, we're living out a dream\\nwe only make it out alone\\ni just keep on hopin' that you call me\\nyou say you wanna see me, but you can't right now\\nyou never took the time to get to know me\\nwas scared of losin' somethin' that we never found\\nwe're running out of reasons, but we can't let go\\nyeah, hollywood is bleeding, but we call it home\\noutside, the winter sky turnin' grey\\ncity up in smoke, it's only ash when it rains\\nhowl at the moon and go to sleep in the day\\nlove for everybody 'til the drugs fade away\\nin the mornin', blocking out the sun with the shades\\nshe gotta check her pulse and tell herself that she okay\\nit seem like dying young is an honor\\nbut who'd be at my funeral? i wonder\\ni go out, and all they eyes on me\\ni show out, do you like what you see?\\nand now they closin' in on me\\nlet 'em sharpen all they teeth\\nthis is more than i can handle\\nblood in my lambo'\\nwish i could go, oh, i'm losin' ho-ope\\ni light a candle, some palo santo\\nfor all these demons, wish i could just go on\\ni just keep on hopin' that you call me\\nyou say you wanna see me, but you can't right now\\nyou never took the time to get to know me\\nwas scared of losin' somethin' that we never found\\nwe're running out of reasons, but we can't let go\\nyeah, hollywood is bleeding, but we call it home\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtYJHRNVrxpe"
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Wt8JAhAxrxpi",
    "outputId": "7d631211-cdd8-42ab-df7f-6f7443998bbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " \"'\": 2,\n",
       " ',': 3,\n",
       " '-': 4,\n",
       " '?': 5,\n",
       " 'a': 6,\n",
       " 'b': 7,\n",
       " 'c': 8,\n",
       " 'd': 9,\n",
       " 'e': 10,\n",
       " 'f': 11,\n",
       " 'g': 12,\n",
       " 'h': 13,\n",
       " 'i': 14,\n",
       " 'j': 15,\n",
       " 'k': 16,\n",
       " 'l': 17,\n",
       " 'm': 18,\n",
       " 'n': 19,\n",
       " 'o': 20,\n",
       " 'p': 21,\n",
       " 'r': 22,\n",
       " 's': 23,\n",
       " 't': 24,\n",
       " 'u': 25,\n",
       " 'v': 26,\n",
       " 'w': 27,\n",
       " 'y': 28,\n",
       " '\\u2005': 29}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cFMZzw1prxpn",
    "outputId": "c7ac3c8a-05a1-491a-e77d-0e05c4b94d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1485\n",
      "Total Vocab:  30\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IBzQR8kArxpr",
    "outputId": "37d678e8-4d7b-4005-a45c-8036d60df980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  1385\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AJB9a-onrxpw",
    "outputId": "6395f839-070d-4f83-ddad-76df650e4bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "print(len(dataX[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2UeC1i_rxpz"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rrOQnF5crxp3",
    "outputId": "208ca369-d5a8-4aee-b03d-9e4e63361e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1385, 100, 1)\n",
      "(1385, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBOl5JQbrxp7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1112 09:10:12.672892 140021016172288 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1112 09:10:12.714646 140021016172288 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1112 09:10:12.719000 140021016172288 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1112 09:10:13.147665 140021016172288 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1112 09:10:13.160891 140021016172288 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1112 09:10:13.200603 140021016172288 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1112 09:10:13.233891 140021016172288 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96J09Tqdrxp_"
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"/home/debjoy/towards_vortex/beginnersNNS/RNN/models_seqgen/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "24parC0brxqC",
    "outputId": "5bead389-187c-4273-cf09-07772c16a92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9926\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.99255, saving model to /home/debjoy/towards_vortex/beginnersNNS/RNN/models_seqgen/weights-improvement-01-2.9926.hdf5\n",
      "Epoch 2/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9729\n",
      "\n",
      "Epoch 00002: loss improved from 2.99255 to 2.97285, saving model to /home/debjoy/towards_vortex/beginnersNNS/RNN/models_seqgen/weights-improvement-02-2.9729.hdf5\n",
      "Epoch 3/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9659\n",
      "\n",
      "Epoch 00003: loss improved from 2.97285 to 2.96586, saving model to /home/debjoy/towards_vortex/beginnersNNS/RNN/models_seqgen/weights-improvement-03-2.9659.hdf5\n",
      "Epoch 4/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9653\n",
      "\n",
      "Epoch 00004: loss improved from 2.96586 to 2.96532, saving model to /home/debjoy/towards_vortex/beginnersNNS/RNN/models_seqgen/weights-improvement-04-2.9653.hdf5\n",
      "Epoch 5/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9669\n",
      "\n",
      "Epoch 00005: loss did not improve from 2.96532\n",
      "Epoch 6/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9624\n",
      "\n",
      "Epoch 00006: loss improved from 2.96532 to 2.96239, saving model to /home/debjoy/towards_vortex/beginnersNNS/RNN/models_seqgen/weights-improvement-06-2.9624.hdf5\n",
      "Epoch 7/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9624\n",
      "\n",
      "Epoch 00007: loss did not improve from 2.96239\n",
      "Epoch 8/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9651\n",
      "\n",
      "Epoch 00008: loss did not improve from 2.96239\n",
      "Epoch 9/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9686\n",
      "\n",
      "Epoch 00009: loss did not improve from 2.96239\n",
      "Epoch 10/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9565\n",
      "\n",
      "Epoch 00010: loss improved from 2.96239 to 2.95645, saving model to /home/debjoy/towards_vortex/beginnersNNS/RNN/models_seqgen/weights-improvement-10-2.9565.hdf5\n",
      "Epoch 11/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9595\n",
      "\n",
      "Epoch 00011: loss did not improve from 2.95645\n",
      "Epoch 12/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9628\n",
      "\n",
      "Epoch 00012: loss did not improve from 2.95645\n",
      "Epoch 13/20\n",
      "1385/1385 [==============================] - 5s 3ms/step - loss: 2.9611\n",
      "\n",
      "Epoch 00013: loss did not improve from 2.95645\n",
      "Epoch 14/20\n",
      "1385/1385 [==============================] - 5s 3ms/step - loss: 2.9581\n",
      "\n",
      "Epoch 00014: loss did not improve from 2.95645\n",
      "Epoch 15/20\n",
      "1385/1385 [==============================] - 5s 4ms/step - loss: 2.9631\n",
      "\n",
      "Epoch 00015: loss did not improve from 2.95645\n",
      "Epoch 16/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9574\n",
      "\n",
      "Epoch 00016: loss did not improve from 2.95645\n",
      "Epoch 17/20\n",
      "1385/1385 [==============================] - 5s 3ms/step - loss: 2.9590\n",
      "\n",
      "Epoch 00017: loss did not improve from 2.95645\n",
      "Epoch 18/20\n",
      "1385/1385 [==============================] - 5s 3ms/step - loss: 2.9621\n",
      "\n",
      "Epoch 00018: loss did not improve from 2.95645\n",
      "Epoch 19/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9529\n",
      "\n",
      "Epoch 00019: loss improved from 2.95645 to 2.95293, saving model to /home/debjoy/towards_vortex/beginnersNNS/RNN/models_seqgen/weights-improvement-19-2.9529.hdf5\n",
      "Epoch 20/20\n",
      "1385/1385 [==============================] - 4s 3ms/step - loss: 2.9583\n",
      "\n",
      "Epoch 00020: loss did not improve from 2.95293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f58d5157978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4azvZpJRrxqG"
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "PU-_LzarrxqL",
    "outputId": "fb5c4079-2b9d-497f-b25f-2aa363900f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  it rains\n",
      "howl at the moon and go to sleep in the day\n",
      "love for everybody 'til the drugs fade away\n",
      "in \"\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGXgDy6PrxqP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "seqgen_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
