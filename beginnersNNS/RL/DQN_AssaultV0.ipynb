{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KqdYWn8rzg8_"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvo0yVoyzg9C"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf      # Deep Learning library\n",
    "import numpy as np           # Handle matrices\n",
    "\n",
    "import random                # Handling random number generation\n",
    "import time                  # Handling time calculation\n",
    "from skimage import transform# Help us to preprocess the frames\n",
    "\n",
    "from collections import deque # Ordered collection with ends\n",
    "import matplotlib.pyplot as plt # Display graphs\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z4-r6Y270D-W"
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRiLTM-Ozg9G"
   },
   "source": [
    "#### Playing with the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xADoJYJSzg9I"
   },
   "outputs": [],
   "source": [
    "env = gym.make('Assault-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-TfpdW60zg9N",
    "outputId": "709644a1-8609-41dc-91d2-312d357dc198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(250, 160, 3)\n",
      "Num Action space: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation space: {}\".format(env.observation_space)) # No. of possible board states\n",
    "print(\"Num Action space: {}\".format(env.action_space.n))      # No. of possible actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dU9is6qMzg9S"
   },
   "outputs": [],
   "source": [
    "# Comment for Colab\n",
    "env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCUOlhd0zg9W"
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    obs, reward, done, info = env.step(env.action_space.sample())\n",
    "    # Comment for Colab\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-rW3uVIfzg9a",
    "outputId": "7daf8450-387f-459e-bca0-c9fb720ee745",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = env.action_space.sample()\n",
    "print(x)\n",
    "print(env.action_space.contains(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybZeHY5_zg9e"
   },
   "source": [
    "#### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Vx8V9rNvzg9f",
    "outputId": "0b03e746-02a1-4f2f-9e3d-bc90f0497d8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fea8b06dcf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = env.reset()\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "WRIGh8ikzg9j",
    "outputId": "02b15d49-dafc-45d8-d4ff-a9b256242622"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collection observation frame for pre-processing test\n",
    "env.reset()\n",
    "obs, reward, done, info = env.step(env.action_space.sample())\n",
    "env.close()\n",
    "\n",
    "plt.imshow(cv2.cvtColor(obs, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WW6Fv36zg9n"
   },
   "outputs": [],
   "source": [
    "def preprocessing(obs):\n",
    "    bw_frame = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
    "    frame = bw_frame[50:224, :]\n",
    "    normalized_frame = frame/255.0\n",
    "    preprocessed_frame = transform.resize(normalized_frame, [84,84])\n",
    "    return preprocessed_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "PNEdUEA8zg9q",
    "outputId": "d6a641db-52d8-4222-8f2c-60c70fc6e916"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocessing(obs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ixuyeKmzg9v"
   },
   "source": [
    "#### Part 2: Stacking Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4NRX6qCzg9w"
   },
   "outputs": [],
   "source": [
    "stack_size = 4\n",
    "stacked_frames= deque([np.zeros((84, 84), dtype = np.int) for i in range(stack_size)], maxlen = 4)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    frame = preprocessing(state)\n",
    "    if is_new_episode:\n",
    "        # Reinitialize with 4 repeated frames\n",
    "        for _ in range(4):\n",
    "            stacked_frames.append(frame)\n",
    "    else:\n",
    "        # Just append the new frame(The last frame will get removed)\n",
    "        stacked_frames.append(frame)\n",
    "    \n",
    "    # Converting Frames Deque to numpy.stack\n",
    "    stacked_state = np.stack(stacked_frames, axis = 2)\n",
    "    return stacked_state, stacked_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOtXYq3Bzg93"
   },
   "source": [
    "#### Part 3: Set Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2HRFYmyzg94"
   },
   "outputs": [],
   "source": [
    "state_size = [84,84,4]      # Our input is a stack of 4 frames hence 84x84x4 (Width, height, channels) \n",
    "action_size = env.action_space.n\n",
    "learning_rate =  0.0002      # Alpha (aka learning rate)\n",
    "\n",
    "### TRAINING HYPERPARAMETERS\n",
    "total_episodes = 500        # Total episodes for training\n",
    "max_steps = 10000              # Max possible steps in an episode\n",
    "batch_size = 64             \n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Q learning hyperparameters\n",
    "gamma = 0.95               # Discounting rate\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 1000000          # Number of experiences the Memory can keep\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE (already)TRAINED AGENT\n",
    "training = True\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWG4NH2vzg98"
   },
   "source": [
    "#### Part 4: Create the Tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrgL_OL2zg99"
   },
   "outputs": [],
   "source": [
    "# Using a class DQNet for this\n",
    "class DQNet:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name = 'DQNet'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Creating Placeholders for TF-graph\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs = tf.placeholder(tf.float32, [None, *state_size], name = \"inputs\")\n",
    "            self.actions = tf.placeholder(tf.float32, [None, self.action_size], name = \"actions\")\n",
    "            self.target_Q = tf.placeholder(tf.float32, [None], name = \"target\")\n",
    "            \n",
    "            # Creating the graph\n",
    "            # 1\n",
    "            self.conv1 = tf.layers.conv2d(inputs = self.inputs, filters = 32, kernel_size = [8,8], strides = [4,4], padding = \"VALID\", kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(), name = \"conv1\")\n",
    "            self.conv1_batchnorm = tf.layers.batch_normalization(self.conv1, training = True, epsilon = 1e-5, name = \"batch_norm\")\n",
    "            self.conv1_out = tf.nn.elu(self.conv1_batchnorm, name=\"conv1_out\")\n",
    "            \n",
    "            # 2\n",
    "            self.conv2 = tf.layers.conv2d(inputs = self.conv1_out, filters = 64, kernel_size = [4,4], strides = [2,2], padding = \"VALID\", kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), name = \"conv2\")\n",
    "            self.conv2_batchnorm = tf.layers.batch_normalization(self.conv2, training = True, epsilon = 1e-5, name = 'batch_norm2')\n",
    "            self.conv2_out = tf.nn.elu(self.conv2_batchnorm, name=\"conv2_out\")\n",
    "            \n",
    "            # 3\n",
    "            self.conv3 = tf.layers.conv2d(inputs = self.conv2_out, filters = 128, kernel_size = [4,4], strides = [2,2], padding = \"VALID\", kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), name = \"conv3\")\n",
    "            self.conv3_batchnorm = tf.layers.batch_normalization(self.conv3, training = True, epsilon = 1e-5, name = 'batch_norm3')\n",
    "            self.conv3_out = tf.nn.elu(self.conv3_batchnorm, name=\"conv3_out\")\n",
    "            \n",
    "            # Fully-Connected\n",
    "            self.flatten = tf.layers.flatten(self.conv3_out)\n",
    "            self.fc = tf.layers.dense(inputs = self.flatten, units = 512, activation = tf.nn.elu, kernel_initializer=tf.contrib.layers.xavier_initializer(), name=\"fc1\")\n",
    "            self.output = tf.layers.dense(inputs = self.fc, units = 7, activation = None, kernel_initializer=tf.contrib.layers.xavier_initializer(), name=\"fc2\")\n",
    "            \n",
    "            # Q is our predicted Q value.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions), axis=1)\n",
    "            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n",
    "            \n",
    "            self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i43s-NsGzg-B",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1222 21:57:16.559853 140647279589120 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1222 21:57:16.561385 140647279589120 deprecation.py:323] From <ipython-input-15-88ed69d8faf0>:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W1222 21:57:17.050407 140647279589120 deprecation.py:323] From <ipython-input-15-88ed69d8faf0>:17: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W1222 21:57:17.242495 140647279589120 deprecation.py:323] From <ipython-input-15-88ed69d8faf0>:31: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W1222 21:57:17.486866 140647279589120 deprecation.py:323] From <ipython-input-15-88ed69d8faf0>:32: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W1222 21:57:18.150044 140647279589120 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Instantiate the DQNetwork\n",
    "DQNet = DQNet(state_size, action_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaEEqJ8czg-F"
   },
   "source": [
    "#### Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPH6lkM8zg-G"
   },
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen = max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        index = np.random.choice(np.arange(buffer_size),\n",
    "                                size = batch_size,\n",
    "                                replace = False)\n",
    "        \n",
    "        return [self.buffer[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDK1j_7Vzg-K"
   },
   "outputs": [],
   "source": [
    "# Instantiate Memory\n",
    "memory = Memory(max_size = memory_size)\n",
    "\n",
    "# Render new environment\n",
    "state = env.reset()\n",
    "for i in range(pretrain_length):\n",
    "    # First Step\n",
    "    if i==0:\n",
    "        # Obtain Stacked States\n",
    "        stacked_state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        \n",
    "    # Random Action\n",
    "    action = env.action_space.sample()\n",
    "    action_state = np.zeros(7)\n",
    "    action_state[action] = 1\n",
    "\n",
    "    # Take action and observe reward\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    # If episode finished\n",
    "    if done:\n",
    "        # If episode is finished, next state is zero-array\n",
    "        next_stacked_state = np.zeros(stacked_state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((stacked_state, action_state, reward, next_stacked_state, done))\n",
    "        # Update stacked state\n",
    "        state = env.reset()\n",
    "        stacked_state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        \n",
    "    else:\n",
    "        next_stacked_state, stacked_frames = stack_frames(stacked_frames, obs, False)\n",
    "        # Add experience to memory\n",
    "        memory.add((stacked_state, action_state, reward, next_stacked_state, done))\n",
    "        # Update stacked state\n",
    "        stacked_state = next_stacked_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uREV_RtSzg-P",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"tensorboard/dqn/1\")\n",
    "\n",
    "# Losses\n",
    "tf.summary.scalar(\"Loss\", DQNet.loss)\n",
    "write_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KD8bZ6U1zg-V"
   },
   "source": [
    "#### Choosing Action using an epsilon-greedy strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "weB1bzTVzg-Y"
   },
   "outputs": [],
   "source": [
    "def predict_action(explore_start, explore_stop, decay_rate, decay_step, state):\n",
    "    ## EPSILON GREEDY STRATEGY\n",
    "    # Choose action a from state s using epsilon greedy.\n",
    "    ## First we randomize a number\n",
    "    exp_exp_tradeoff = np.random.rand()\n",
    "\n",
    "    # Here we'll use an improved version of our epsilon greedy strategy used in Q-learning notebook\n",
    "    explore_probability = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * decay_step)\n",
    "    \n",
    "    if (explore_probability > exp_exp_tradeoff):\n",
    "        # Make a random action (exploration)\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "    else:\n",
    "        # Get action from Q-network (exploitation)\n",
    "        # Estimate the Qs values state\n",
    "        Qs = sess.run(DQNet.output, feed_dict = {DQNet.inputs: state.reshape((1, *state.shape))})\n",
    "        \n",
    "        # Take the biggest Q value (= the best action)\n",
    "        choice = np.argmax(Qs)\n",
    "        action = choice\n",
    "        \n",
    "    return action, explore_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ALTLNWhszg-d",
    "outputId": "c8acd66e-18cf-4d25-a71b-791a2987fc94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), array([0., 0., 0., 1., 0., 0., 0.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False), (array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), array([1., 0., 0., 0., 0., 0., 0.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False), (array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), array([0., 0., 0., 0., 1., 0., 0.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False), (array([[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        ...,\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
      "\n",
      "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        ...,\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
      "\n",
      "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        ...,\n",
      "        [4.64093597e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        ...,\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
      "\n",
      "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        ...,\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
      "\n",
      "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        ...,\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]), array([0., 0., 0., 0., 0., 0., 1.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False), (array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), array([0., 0., 0., 0., 1., 0., 0.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False), (array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), array([0., 1., 0., 0., 0., 0., 0.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False), (array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), array([0., 0., 0., 0., 0., 1., 0.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False), (array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), array([0., 0., 0., 0., 1., 0., 0.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False), (array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), array([0., 0., 1., 0., 0., 0., 0.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False), (array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), array([0., 0., 0., 0., 0., 0., 1.]), 0.0, array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]]), False)]\n"
     ]
    }
   ],
   "source": [
    "print(memory.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "j4IAyh9azg-h",
    "outputId": "26c5599c-d8cf-4ff0-8075-22184379aa98",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Total reward: 126.0 Training loss: 1.6658 Explore P: 0.9670\n",
      "Model Saved\n",
      "Episode: 1 Total reward: 231.0 Training loss: 1.7730 Explore P: 0.9195\n",
      "Episode: 2 Total reward: 336.0 Training loss: 2.4660 Explore P: 0.8494\n",
      "Episode: 3 Total reward: 273.0 Training loss: 2.6623 Explore P: 0.7817\n",
      "Episode: 4 Total reward: 210.0 Training loss: 4.8224 Explore P: 0.7229\n"
     ]
    }
   ],
   "source": [
    "# Saver will help us to save our model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if training == True:\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Decay step initialize for epsilon-greedy\n",
    "        decay_step = 0\n",
    "        env.reset()\n",
    "        \n",
    "        for episode in range(total_episodes):\n",
    "            # print(\"new_episode.................................................\")\n",
    "            step = 0\n",
    "            \n",
    "            #Initialising Episode rewards\n",
    "            episode_rewards = []\n",
    "            \n",
    "            # New Episode\n",
    "            state = env.reset()\n",
    "            \n",
    "            # Stack frames\n",
    "            stacked_state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "            \n",
    "            while step < max_steps:\n",
    "                step += 1\n",
    "                # print(step)\n",
    "                decay_step += 1\n",
    "                \n",
    "                action, explore_probability = predict_action(explore_start, explore_stop, decay_rate, decay_step, stacked_state)\n",
    "                \n",
    "                \n",
    "                # Take action and observe reward\n",
    "                obs, reward, done, info = env.step(action)\n",
    "                \n",
    "                # Add the reward to total reward\n",
    "                episode_rewards.append(reward)\n",
    "                # If the game is finished\n",
    "                # print(done)\n",
    "                if done:\n",
    "                    # print(\"1\")\n",
    "                    # the episode ends so no next state\n",
    "                    next_state = np.zeros(obs.shape, dtype=np.uint16)\n",
    "                    \n",
    "                    # Obtain stacked state\n",
    "                    next_stacked_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "\n",
    "                    # Get the Total Rewards\n",
    "                    total_reward = np.sum(episode_rewards)\n",
    "                    print('Episode: {}'.format(episode), 'Total reward: {}'.format(total_reward), 'Training loss: {:.4f}'.format(loss),'Explore P: {:.4f}'.format(explore_probability))\n",
    "                \n",
    "                    action_state = np.zeros(7)\n",
    "                    action_state[action] = 1\n",
    "                    \n",
    "                    # Add to memory\n",
    "                    memory.add((stacked_state, action_state, reward, next_stacked_state, done))\n",
    "                    step = max_steps\n",
    "                    \n",
    "                else:\n",
    "                    # print(\"2\")\n",
    "                    # Get the next state\n",
    "                    next_state = obs\n",
    "                    \n",
    "                    # Obtain Stacked next state\n",
    "                    next_stacked_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "                    \n",
    "                    # Add experience to memory\n",
    "                    memory.add((stacked_state, action_state, reward, next_stacked_state, done))\n",
    "                \n",
    "                    # Update state\n",
    "                    stacked_state = next_stacked_state\n",
    "                    \n",
    "                ### LEARNING PART            \n",
    "                # Obtain random mini-batch from memory\n",
    "                batch = memory.sample(batch_size)\n",
    "                states_mb = np.array([each[0] for each in batch], ndmin=3)\n",
    "                actions_mb = np.array([each[1] for each in batch])\n",
    "                rewards_mb = np.array([each[2] for each in batch]) \n",
    "                next_states_mb = np.array([each[3] for each in batch], ndmin=3)\n",
    "                dones_mb = np.array([each[4] for each in batch])\n",
    "\n",
    "                target_Qs_batch = []\n",
    "\n",
    "                 # Get Q values for next_state \n",
    "                Qs_next_state = sess.run(DQNet.output, feed_dict = {DQNet.inputs: next_states_mb})\n",
    "                # Set Q_target = r if the episode ends at s+1, otherwise set Q_target = r + gamma*maxQ(s', a')\n",
    "                for i in range(0, len(batch)):\n",
    "                    terminal = dones_mb[i]\n",
    "\n",
    "                    # If we are in a terminal state, only equals reward\n",
    "                    if terminal:\n",
    "                        target_Qs_batch.append(rewards_mb[i])\n",
    "                        \n",
    "                    else:\n",
    "                        target = rewards_mb[i] + gamma * np.max(Qs_next_state[i])\n",
    "                        target_Qs_batch.append(target)\n",
    "                        \n",
    "\n",
    "                targets_mb = np.array([each for each in target_Qs_batch])\n",
    "\n",
    "                loss, _ = sess.run([DQNet.loss, DQNet.optimizer],\n",
    "                                    feed_dict={DQNet.inputs: states_mb,\n",
    "                                               DQNet.target_Q: targets_mb,\n",
    "                                               DQNet.actions: actions_mb})\n",
    "\n",
    "                # Write TF Summaries\n",
    "                summary = sess.run(write_op, feed_dict={DQNet.inputs: states_mb,\n",
    "                                                   DQNet.target_Q: targets_mb,\n",
    "                                                   DQNet.actions: actions_mb})\n",
    "                writer.add_summary(summary, episode)\n",
    "                writer.flush()\n",
    "\n",
    "            # Save model every 5 episodes\n",
    "            if episode % 5 == 0:\n",
    "                save_path = saver.save(sess, \"./models/model.ckpt\")\n",
    "                print(\"Model Saved\")\n",
    "     \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DQN-AssaultV0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
